data_set_size:10728
input_size:10
batch_size:64
accuracy of each sign:
sign 0, accuracy 0.875000 (21 / 24)
sign 1, accuracy 1.000000 (15 / 15)
sign 2, accuracy 1.000000 (17 / 17)
sign 3, accuracy 1.000000 (13 / 13)
sign 4, accuracy 1.000000 (9 / 9)
sign 5, accuracy 1.000000 (12 / 12)
sign 6, accuracy 1.000000 (11 / 11)
sign 7, accuracy 0.937500 (15 / 16)
sign 8, accuracy 1.000000 (7 / 7)
sign 9, accuracy 0.937500 (15 / 16)
sign 10, accuracy 1.000000 (21 / 21)
sign 11, accuracy 0.941176 (16 / 17)
sign 12, accuracy 1.000000 (8 / 8)
sign 13, accuracy 1.000000 (7 / 7)
sign 14, accuracy 1.000000 (11 / 11)
sign 15, accuracy 1.000000 (10 / 10)
sign 16, accuracy 1.000000 (8 / 8)
sign 17, accuracy 1.000000 (11 / 11)
sign 18, accuracy 1.000000 (3 / 3)
sign 19, accuracy 0.928571 (13 / 14)
sign 20, accuracy 1.000000 (14 / 14)
sign 21, accuracy 1.000000 (15 / 15)
sign 22, accuracy 1.000000 (8 / 8)
sign 23, accuracy 1.000000 (13 / 13)
overall accuracy: 0.97667
loss: 2.247258
NNet:3 x 64
Epoch: 1200
NNet output size: 32
classes cnt 24
learning rate 0.000064
weight_decay 0.000008
dropout 0.500000RNN(
  (rnn): LSTM(30, 64, num_layers=3, batch_first=True, dropout=0.5)
  (out): Sequential(
    (0): LeakyReLU(0.01)
    (1): Linear(in_features=64, out_features=64, bias=True)
    (2): LeakyReLU(0.01)
    (3): Dropout(p=0.5)
    (4): Linear(in_features=64, out_features=32, bias=True)
    (5): Dropout(p=0.5)
    (6): LeakyReLU(0.01)
    (7): Linear(in_features=32, out_features=24, bias=True)
    (8): Softmax()
  )
)