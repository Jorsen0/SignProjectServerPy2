# coding:utf-8
import json
import os
import pickle
import threading
import time

import numpy as np
import queue
import torch
import torch.nn.functional as F

import my_pickle
from algorithm_models.classify_model import CNN, get_max_index
from algorithm_models.verify_model import SiameseNetwork

CURR_WORK_DIR = os.path.dirname(__file__)
CURR_DATA_DIR = os.path.join(CURR_WORK_DIR, 'models_param')

torch.set_num_threads(1)

class OnlineRecognizer(threading.Thread):
    """
    在线识别线程
    主线程将数据放入该线程的队列 不断取出进行识别
    """
    def __init__(self, stop_flag):
        threading.Thread.__init__(self, name='recognize_queue')
        self.data_queue = queue.Queue()
        # 存放已经处理好的numpy对象 供模型识别
        self.stop_flag = stop_flag
        torch.set_num_threads(1)
        self.cnn_model = CNN()
        load_model_param(self.cnn_model, 'cnn')
        self.cnn_model.double()
        self.cnn_model.eval()

        self.verify_model = VerifyModel()

        self.recognize_data_history = []
        self.skip_cnt = 0

        # 重复标记 可能有多个有效的识别挨在一起
        # 只要有一个有效识别剩下几个有效的都可以跳过
        # 直到遇到一个无效的被重新置位

    def run(self):
        while not self.stop_flag.is_set():
            time.sleep(0.001)
            while not self.data_queue.empty():
                # 转换为Variable
                new_msg = self.data_queue.get()
                if self.skip_cnt != 0:
                    self.skip_cnt -= 1
                    continue
                data_mat = np.array([new_msg.T])
                # print (data_mat)
                data_mat = torch.from_numpy(data_mat).double()
                # 分类并检验
                classify_output = self.cnn_model(data_mat)
                predict_index, predict_prob = get_max_index(classify_output)
                if predict_prob < 0.94:
                    return_info = {
                        'index': predict_index,
                        "verify_result": 'low Probability',
                        'predict_prob': predict_prob,
                        'diff': 99,
                        'threshold': 0
                    }
                    continue
                verify_result, diff, threshold = self.verify_model.verify_correctness(data_mat, predict_index)

                return_info = {
                    'index': predict_index,
                    'diff': diff,
                    'predict_prob': predict_prob,
                    'verify_result': str(verify_result),
                    'threshold': threshold
                }
                # return all
                print(json.dumps(return_info))

                if verify_result:
                    if predict_index != 62:
                        print(json.dumps(return_info))
                    self.skip_cnt = 7

                # return_info['data'] = new_msg
                # self.recognize_data_history.append(return_info)

        print("end")

    def add_new_data(self, data):
        self.data_queue.put(data)

    def clean_data_queue(self):
        self.data_queue = queue.Queue()

    def save_history_recognized_data(self):
        # 保存历史数据
        time_tag = time.strftime("%m-%d %H_%M", time.localtime(time.time()))
        file_name = os.path.join(CURR_DATA_DIR, 'history_recognized_data_' + time_tag)
        file_ = open(file_name, 'wb')
        pickle.dump(self.recognize_data_history, file_)
        file_.close()

    def stop_thread(self):
        #  将识别时输入算法的数据保存起来
        # self.save_history_recognized_data()
        self.recognize_data_history = []
        self.stop_flag.set()

class VerifyModel:
    """
    验证模型
    """

    def __init__(self):
        self.verify_model = SiameseNetwork(False)
        load_model_param(self.verify_model, 'verify')
        self.verify_model.single_output()

        vector_file_path = os.path.join(CURR_DATA_DIR, 'reference_verify_vector')
        file_ = open(vector_file_path, 'rb')
        self.reference_vectors = pickle.load(file_)  # reference vector
        file_.close()

    def verify_correctness(self, data, predict_index):
        """
        :return: 验证的正误以及 差异程度
        """
        data_vector = self.verify_model(data)
        reference_vector = self.reference_vectors[predict_index][0].double()
        threshold = self.reference_vectors[predict_index][1] * 2.5 + 0.09
        diff = F.pairwise_distance(data_vector, reference_vector)
        diff = torch.squeeze(diff).item()
        if diff > threshold:
            return False, diff, threshold
        else:
            return True, diff, threshold


'''

'''


def load_model_param(model, model_name):
    for root, dirs, files in os.walk(CURR_DATA_DIR):
        for file_ in files:
            file_name_split = os.path.splitext(file_)
            if file_name_split[1] == '.pkl' and file_name_split[0].startswith(model_name):
                print('load model params %s' % file_name_split[0])
                file_ = os.path.join(CURR_DATA_DIR, file_)
                model.load_state_dict(torch.load(file_))
                model.double()
                model.eval()
                return model


def main():
    # load model
    stop_event = threading.Event()
    online_recognizer = OnlineRecognizer(stop_event)
    online_recognizer.start()

    while True:
        read_ = input()
        if read_ == 'end':
            if online_recognizer is not None:
                online_recognizer.stop_thread()
            print("end")
            return
        data_mat = my_pickle.loads(read_)
        online_recognizer.add_new_data(data_mat)


if __name__ == '__main__':
    main()

'''
0.4778823528427603,0.5031643423206198,0.3610456674018531,0.6407393918401348,0.49743290328520884,0.522696589870984,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47908033968227687,0.5070476039096858,0.3606242794112087,0.6424352234361819,0.4991052904768168,0.5227981093901695,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4802362457815185,0.5105967008096319,0.3606732873414439,0.6428580288712229,0.49959645714822054,0.5213546456430129,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4829459135866419,0.5082825532974065,0.36365600141425086,0.6393242894105033,0.4988437091005714,0.5191528907790867,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.48322937569239355,0.5038955161546659,0.3635495225731382,0.6354197939268912,0.4992226362139736,0.5191441772276189,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.48037733235017854,0.5012990990603,0.36008771431796593,0.6339474552884707,0.5019201552684734,0.5214989843368311,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47550923795831646,0.5052351936020694,0.3555322993132044,0.6321530759737966,0.5048321381312036,0.5241636461652867,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4702742248337761,0.5074044659307085,0.3563190285456911,0.626737619424524,0.5070862399291483,0.5263390640852075,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.46738821472598235,0.5086141110684907,0.356773402197617,0.6210183532434348,0.5092352838044554,0.5278089805994267,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.46379440105193753,0.5122480053411025,0.3522451977788882,0.617613377887566,0.511019968384114,0.5276944059929154,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.46242897231835045,0.5134559945950284,0.34612378556378004,0.6197805899283518,0.5112416309625377,0.5238951146744536,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.46309770545667606,0.5049042630153131,0.3457193484884488,0.6309675378464246,0.5089982769863217,0.5157549214768834,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4644014236029002,0.49643236848361416,0.34814167528261225,0.6402519392717798,0.5066136227814755,0.5107371569669408,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.46426187563832993,0.49384255734006616,0.3428038587869392,0.644427095100671,0.5031185481004972,0.5091224860150877,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4635708873994906,0.4876077706905245,0.34002429368058795,0.6450088044793638,0.49790296305959664,0.510047353852648,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.46507458165563886,0.48777323598390276,0.3386582245845445,0.6488394061845439,0.49217861494844567,0.5147462465135507,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4658460765784627,0.49184439203298813,0.33941413202653736,0.6537183687835048,0.48752228503627165,0.5172900914823099,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4684664351873383,0.4926391693917232,0.34343785510340497,0.6546274204562255,0.48315967180191877,0.5181383234701203,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4712865871663098,0.4949224515219441,0.3486322964438767,0.6550849557403224,0.48217262852288545,0.5206964646617018,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47304262880923637,0.5011811063451593,0.35460732832573744,0.6540627613071018,0.4856517142661983,0.5245940056315673,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4741170084709875,0.5054030972943298,0.358646651235499,0.6521579226443468,0.4891922669262053,0.5263043317983439,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47541944091199134,0.5065429461948772,0.3613907388425448,0.650823131218726,0.4913157199338331,0.5258600711268253,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47671392417046565,0.5074871692697188,0.36287190661423874,0.6498741912512059,0.4929007280630166,0.524750554513989,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47826020333302216,0.5094985640630398,0.36489530047886354,0.647894860606088,0.49495186994880613,0.5234925356732276,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4789657259146311,0.5095298324256289,0.36521347504131374,0.6457734012431849,0.49658761002407714,0.5229841870562137,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4791281881483814,0.5071257821430781,0.36280356822379617,0.6442841697226747,0.4983836378607855,0.5226377663882336,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47737057363764723,0.5066604260256374,0.35857721843264817,0.6443182730169027,0.5001179803117249,0.52171106245042,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.475691504620955,0.5070975764329313,0.3553161189963959,0.6442903445480823,0.5001531838186867,0.5211610614236755,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47393096953617986,0.5065590097336672,0.3530815356207332,0.6440283836756056,0.49948856876595477,0.5204944302359528,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47226059371417506,0.5038349078747575,0.3526269266879638,0.6439190895493991,0.4986758830851336,0.5192736625287504,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47135606093316285,0.5029697070944599,0.35324690596993713,0.6443076471006365,0.49864324337701793,0.5190395390202209,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47142856622323825,0.5032338923733519,0.35309526746632447,0.6441479564195878,0.4988285586986188,0.5198149756070187,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4715631084217986,0.5035295980608716,0.3537332207787939,0.6440048467607598,0.49882014121368573,0.5207228357430294,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4716060685974971,0.5031365293333698,0.3561012832547875,0.6443797278391934,0.4979772639634966,0.5215533065698237,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4723656495361603,0.5036174390359881,0.35775609898354177,0.6450650710874689,0.49744858807965275,0.5221959977412288,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4730066910640813,0.505655582947816,0.3581805990980702,0.6452503853093966,0.498255092370775,0.5227225830033883,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4736999602875627,0.5068985450549405,0.35840856484621947,0.6448158950520794,0.49913369788207557,0.5229170584506707,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47429400504750735,0.5066399897811596,0.3583117146953826,0.6440481314930423,0.4989064771933717,0.5226909401441753,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4749323609525951,0.5057924556696862,0.3580901193543132,0.6434560116649019,0.4986841720588463,0.5220379321863534,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4748884152871085,0.5061747567559702,0.3589151815399782,0.6434786923826527,0.49918345100103473,0.5216403347957749,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4742634287583851,0.507222661606359,0.3605133872718505,0.6432106956041644,0.4999169844793876,0.5213586384905093,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4738977533091814,0.5070123350489307,0.3615051316756649,0.6421772628752984,0.5000494195756674,0.5212404867803173,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4730593299242553,0.5062717446576629,0.36223581772421065,0.6414049730955251,0.4997134741108386,0.5210533411037672,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47176925526413793,0.5053625296052344,0.3623993771238922,0.6411526954719832,0.49898051679112365,0.5210426536835676,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4707501021890575,0.5051359197014247,0.36160909728958596,0.641414735726972,0.4979676984449951,0.5210988876065982,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.46986047575689377,0.5054092958684113,0.361029040888915,0.6415145351377101,0.49686372280656377,0.5215049656833403,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4698022176470006,0.5048110733888023,0.3603217724140165,0.6413319114159256,0.4954148444712452,0.5219307190495166,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4707931700507262,0.5034892912101182,0.3589794559885791,0.6414049575025317,0.4942947406746597,0.5222898705002624,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4719063395042379,0.5030561237163831,0.35762017795324474,0.6419152084448609,0.49348926875700766,0.5226131485022343,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.472237052908441,0.5036783462542208,0.3571755185482649,0.6421965287274828,0.49305587109193255,0.523000702204973,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47331700613495425,0.5037902371106202,0.3571317670059644,0.6423369322931742,0.49304102590412824,0.5233207176543034,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4745831777728923,0.5037378818730824,0.3568935273276505,0.6425674647785726,0.49333770904928587,0.5235762428254137,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47517619135809175,0.5040282594245828,0.3564891615495446,0.6426886946324954,0.49408782047506405,0.5235717854664986,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4749394649634189,0.505304632285622,0.3560469048610571,0.6425838742778653,0.49575299390350297,0.5232966679108791,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.474662852338016,0.5059631934144936,0.3563812318098973,0.6423041699963832,0.4969663090300632,0.5229587888885662,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4742574733979104,0.5054946017293054,0.3580387960466866,0.6417151588441196,0.4973180635168489,0.5227607875435861,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4737948218376997,0.5049319265334008,0.3585340016195373,0.6414254197625775,0.4973473212380156,0.5224039062247604,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4739301635230087,0.5046493037937299,0.35799593215484093,0.6416784571901641,0.4971431276181451,0.5219869383422663,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.47364916187851624,0.5047768947737011,0.3571401622542425,0.6419427073975889,0.4967737413919272,0.521638408475456,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.472585554076999,0.5047263859199324,0.35674833765806546,0.641755852304399,0.49655699650953566,0.5216182138110496,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.44271308087689365,0.546660091273607,0.3335546729468753,0.64206697930278,0.4962634511800083,0.5219133455909443,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.44237159561245654,0.5464071161818835,0.3338935843073017,0.6420425904434737,0.4958879606708237,0.5221006156248821,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4282475690216075,0.5677282943001372,0.3219496431928022,0.6423178379639178,0.49627379633324664,0.521988359917894,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;0.4280190447083337,0.5675434712848637,0.32215021476456357,0.6423059475976369,0.49599224110057805,0.5221183353334358,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,;
'''
